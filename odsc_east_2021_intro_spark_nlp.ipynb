{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyLF6TY0k6PplGLC4czFw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevegabriel1/spark_nlp/blob/main/odsc_east_2021_intro_spark_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y_9tcZC25ps"
      },
      "source": [
        "**This is following directly the ODSC East 2021 session 'Introduction to Spark NLP' from John Snow Labs' Veysel Kocaman.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyjp2LoZ2COs",
        "outputId": "e2b68232-0c61-40fb-9e2c-9ff09e667cb9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
        "!bash colab_setup.sh\n",
        "\n",
        "# Install sparknlp-display\n",
        "! pip install spark-nlp-display"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-22 04:31:22--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘colab_setup.sh’\n",
            "\n",
            "\rcolab_setup.sh        0%[                    ]       0  --.-KB/s               \rcolab_setup.sh      100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-22 04:31:22 (23.9 MB/s) - ‘colab_setup.sh’ saved [1594/1594]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.0.2\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 74kB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 23.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 24.5MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp-display\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/d7/bda1c504e36f7a544c40e0a3de108bfe7907e77ab7eb7f188dd3915bcad4/spark_nlp_display-1.6-py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from spark-nlp-display) (5.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spark-nlp-display) (1.1.5)\n",
            "Collecting svgwrite==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/85/1dc25b36c3ac4f3fe285d33065fc0f2ea7bdfb9209d6369e01a3e8ef6252/svgwrite-1.4-py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spark-nlp-display) (1.19.5)\n",
            "Requirement already satisfied: spark-nlp in /usr/local/lib/python3.7/dist-packages (from spark-nlp-display) (3.0.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (54.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->spark-nlp-display) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->spark-nlp-display) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spark-nlp-display) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->spark-nlp-display) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->spark-nlp-display) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->spark-nlp-display) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->spark-nlp-display) (0.7.0)\n",
            "Installing collected packages: svgwrite, spark-nlp-display\n",
            "Successfully installed spark-nlp-display-1.6 svgwrite-1.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR1luwHn21ne",
        "outputId": "972e163b-82bd-4e87-deaf-f28aeb3e7e66"
      },
      "source": [
        "import sparknlp\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 3.0.2\n",
            "Apache Spark version: 3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm4C_h293m_G"
      },
      "source": [
        "## Using Pretrained Pipelines\n",
        "\n",
        "for a more detailed notebook, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/1.SparkNLP_Basics.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NLSGcrZ3t4-"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SykWk1l63yHI",
        "outputId": "c425652d-b339-4203-a005-8a8955927c63"
      },
      "source": [
        "pipeline_dl = PretrainedPipeline('explain_document_dl', lang='en')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_dl download started this may take some time.\n",
            "Approx size to download 169.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}